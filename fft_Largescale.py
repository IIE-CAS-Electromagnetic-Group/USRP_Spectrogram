import datetime
import os
import csv

import numpy as np
import pandas as pd
from scipy.signal import get_window

from utils.dataset_preprocessing import df_normalization_nonlinear
from utils.plot_greyscale import plot_greyscale_for_singledf
from utils.visual_spectrum_single_file import plot_trace_heatmap

# ===== å‚æ•°é…ç½® =====
fs = 20_000_000    # é‡‡æ ·ç‡
fc = 30_000_000    # ä¸­å¿ƒé¢‘ç‡
iq_data_file = "F:\dianji\iq_data.bin"


nfft = 1024
noverlap = nfft // 2
window_name = "hann"
chunk_samples = 50_000_000          # æ¯å—è¯»å–å¤šå°‘ complex æ ·æœ¬ï¼ˆâ‰ˆ400 MBï¼‰
dtype = np.complex64

# =====ğŸ¤ª åˆå§‹åŒ–è¾“å‡ºç›®å½• =====
iqfilename = os.path.basename(iq_data_file).split(".bin")[0]
dir_name = f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
output_dir = f"F:/usrp_spectrum/output/{dir_name}"
os.makedirs(os.path.join(output_dir, "csv"), exist_ok=True)
os.makedirs(os.path.join(output_dir, "img"), exist_ok=True)

# ===== é¢‘ç‡è½´ï¼ˆä¸€æ¬¡æ€§é¢„è®¡ç®—ï¼‰=====
# ä¸åŸè„šæœ¬ä¿æŒä¸€è‡´ï¼šå…ˆæŒ‰ basebandï¼Œå† fftshiftï¼Œå†åŠ ä¸Š fc æˆ RF é¢‘ç‡
f_base = np.fft.fftshift(np.fft.fftfreq(nfft, d=1/fs))
f_rf = f_base + fc
freq_header = ["time"] + [f"{f:.6f}" for f in f_rf]

# ===== STFT å·¥å…· =====
hop = nfft - noverlap
win = get_window(window_name, nfft, fftbins=True).astype(np.float32)

def stft_frames(x: np.ndarray):
    """å°†ä¸€ç»´å¤ä¿¡å·åˆ‡å¸§ï¼ˆæœ‰é‡å ï¼‰å¹¶è¿”å› [n_frames, nfft] çŸ©é˜µè§†å›¾ã€‚"""
    if x.size < nfft:
        return np.empty((0, nfft), dtype=np.complex64)
    n_frames = 1 + (x.size - nfft) // hop
    # ç”¨ stride æ„é€ é‡å å¸§è§†å›¾
    s0 = x.strides[0]
    return np.lib.stride_tricks.as_strided(
        x,
        shape=(n_frames, nfft),
        strides=(hop * s0, s0),
        writeable=False,
    )

def frames_to_spectrum(frames: np.ndarray):
    """é€å¸§åŠ çª— FFTï¼Œè¿”å›å¹…åº¦è°±å¹¶ fftshift åˆ°ä¸åŸè„šæœ¬ç›¸åŒçš„é¢‘ç‡é¡ºåºã€‚"""
    if frames.shape[0] == 0:
        return np.empty((nfft, 0), dtype=np.float32)
    # åŠ çª—
    frames_w = frames * win[None, :]
    # ç›´æ¥åšå…¨é¢‘ FFTï¼Œç„¶åä¸åŸä»£ç ä¸€è‡´åœ°åœ¨é¢‘ç‡ç»´ fftshift
    X = np.fft.fft(frames_w, n=nfft, axis=1)
    mag = np.abs(X).astype(np.float32).T  # [nfft, n_frames]
    mag = np.fft.fftshift(mag, axes=0)
    # è½¬ dBï¼ˆä¸åŸå…¬å¼ä¸€è‡´ï¼‰
    Sxx_dB = 20.0 * np.log10(mag + 1e-10)
    return Sxx_dB

# ===== ä¸»æµç¨‹ï¼šmemmap + åˆ†å—æµå¼è®¡ç®— =====
print(iqfilename)
mm = np.memmap(iq_data_file, dtype=dtype, mode="r")
N = mm.size

# é€å—è¿­ä»£ï¼›å—ä¹‹é—´ä¿ç•™ last_tail ä»¥ä¿è¯å¸§è·¨å—è¿ç»­
last_tail = np.zeros(0, dtype=dtype)
global_frame_idx = 0      # å…¨å±€å¸§è®¡æ•°ï¼Œç”¨äºæ—¶é—´è½´
file_index = 0            # è¾“å‡º CSV çš„ç¼–å·
rows_in_current_file = 0  # å½“å‰ CSV å·²å†™çš„è¡Œæ•°

# æ ¹æ®â€œæœ€å¤šä¸ºåˆ—æ•°çš„ 5 å€è¡Œæ•°â€çš„ç­–ç•¥åˆ‡åˆ†æ–‡ä»¶
max_rows_per_file = len(f_rf) * 5

# æ‰“å¼€ç¬¬ä¸€ä¸ª CSV
def new_csv_writer(idx):
    fn = os.path.join(output_dir, f"csv/{iqfilename}_spectrogram_{idx}.csv")
    f = open(fn, "w", newline="")
    w = csv.writer(f)
    w.writerow(freq_header)
    print(f"writing {fn}")
    return f, w, fn

csv_fh, csv_writer, cur_csv_path = new_csv_writer(file_index)

# æ—¶é—´åˆ»åº¦ï¼šæ¯ä¸€å¸§ä¸­å¿ƒæ—¶é—´ = (frame_start + nfft/2) / fs
while global_frame_idx * hop < N:
    # è¯»å–ä¸€ä¸ªæ•°æ®å—å¹¶ä¸ä¸Šä¸€ä¸ª tail æ‹¼æ¥
    start = global_frame_idx * hop
    # è¯»å¤šä¸€ç‚¹ï¼Œç¡®ä¿æœ¬å—å†…èƒ½å®¹çº³å°½é‡å¤šçš„å®Œæ•´å¸§
    stop = min(N, start + chunk_samples + nfft)  # +nfft åªæ˜¯ä¸Šé™å†—ä½™
    buf = np.asarray(mm[start:stop])
    if last_tail.size:
        buf = np.concatenate([last_tail, buf])

    # åˆ‡å¸§å¹¶è®¡ç®—è°±
    frames = stft_frames(buf)
    if frames.shape[0] == 0:
        break
    Sxx_dB = frames_to_spectrum(frames)

    # è®¡ç®—è¿™äº›å¸§çš„èµ·å§‹æ ·æœ¬ç´¢å¼•ï¼ˆç›¸å¯¹å…¨å±€ä¿¡å·ï¼‰
    # buf çš„ç¬¬ 0 å¸§å¯¹åº”å…¨å±€ start - last_tail.size
    base_start = start - last_tail.size
    frame_starts = base_start + np.arange(frames.shape[0]) * hop
    # å¸§ä¸­å¿ƒæ—¶é—´
    times = (frame_starts + nfft / 2) / fs

    # é€å¸§å†™å…¥ CSVï¼ŒæŒ‰æ–‡ä»¶è¡Œæ•°é˜ˆå€¼åˆ‡æ¢æ–°æ–‡ä»¶
    for k in range(frames.shape[0]):
        if rows_in_current_file >= max_rows_per_file:
            csv_fh.close()
            # åå¤„ç†ï¼šå½’ä¸€åŒ–ä¸ç”»å›¾
            df = pd.read_csv(cur_csv_path)
            df = df_normalization_nonlinear(df)
            plot_greyscale_for_singledf(df, image_name=os.path.join(output_dir, f"img/{os.path.basename(cur_csv_path)[:-4]}.png"))
            plot_trace_heatmap(cur_csv_path, cur_csv_path.replace(".csv", ".html"))
            # æ–°æ–‡ä»¶
            file_index += 1
            rows_in_current_file = 0
            csv_fh, csv_writer, cur_csv_path = new_csv_writer(file_index)

        row = [f"{times[k]:.6f}"] + Sxx_dB[:, k].tolist()
        csv_writer.writerow(row)
        rows_in_current_file += 1
        global_frame_idx += 1

    # è®¡ç®—ä¸‹ä¸€ä¸ªå—çš„ tailï¼šä¿ç•™æœ€å (nfft - hop) + (hop-1) = nfft-1 ä¸ªç‚¹è¶³å¤Ÿäº†ï¼Œ
    # å®é™…ä¿ç•™ nfft-1 èƒ½è¦†ç›–â€œä¸‹ä¸€å—æ‹¼æ¥åâ€çš„ç¬¬ä¸€å¸§å¯¹é½
    keep = min(buf.size, nfft - 1)
    last_tail = buf[-keep:].copy()

# å…³é—­æœ€åä¸€ä¸ª CSV å¹¶åšå¯¹åº”å›¾åƒå’Œ HTML
csv_fh.close()
df = pd.read_csv(cur_csv_path)
df = df_normalization_nonlinear(df)
plot_greyscale_for_singledf(df, image_name=os.path.join(output_dir, f"img/{os.path.basename(cur_csv_path)[:-4]}.png"))
#plot_trace_heatmap(cur_csv_path, cur_csv_path.replace(".csv", ".html"))






print(f"ä¿å­˜å®Œæ¯•ã€‚CSV èµ·å§‹ç›®å½•ï¼š{os.path.join(output_dir, 'csv')}")
